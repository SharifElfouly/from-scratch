{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thinc is this new ML library that I think is a PyTorch/TF type-checked wrapper? Lets find out...\n",
    "\n",
    "https://thinc.ai/docs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: thinc==8.0.0a1 in /home/sharif/.local/lib/python3.6/site-packages (8.0.0a1)\n",
      "Requirement already satisfied: setuptools in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (46.4.0)\n",
      "Requirement already satisfied: dataclasses<1.0,>=0.6; python_version < \"3.7\" in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (0.7)\n",
      "Requirement already satisfied: numpy>=1.7.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (1.18.4)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4.1; python_version < \"3.8\" in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (3.7.4.2)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=0.2.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (1.0.0)\n",
      "Requirement already satisfied: pydantic<2.0.0,>=1.4.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (1.5.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (1.0.2)\n",
      "Requirement already satisfied: contextvars<3,>=2.4; python_version < \"3.7\" in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (2.4)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.0.0 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (2.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (3.0.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/sharif/.local/lib/python3.6/site-packages (from thinc==8.0.0a1) (2.0.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /home/sharif/.local/lib/python3.6/site-packages (from catalogue<3.0.0,>=0.2.0->thinc==8.0.0a1) (1.6.0)\n",
      "Requirement already satisfied: immutables>=0.9 in /home/sharif/.local/lib/python3.6/site-packages (from contextvars<3,>=2.4; python_version < \"3.7\"->thinc==8.0.0a1) (0.14)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/sharif/.local/lib/python3.6/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<3.0.0,>=0.2.0->thinc==8.0.0a1) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install \"thinc==8.0.0a1\";\n",
    "# pip3 install thinc[blis,cuda100]==8.0.0a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a GPU you should install the thinc-cuda version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import prefer_gpu\n",
    "prefer_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type checking\n",
    "\n",
    "This is probably the coolest Thinc feature. Does it natively support JN?\n",
    "\n",
    "It makes sure that the ouptut matches the input of the next layer for example. Very helpful.\n",
    "\n",
    "You can also define your own datatypes.\n",
    "\n",
    "https://thinc.ai/static/fbdab0fcfb4cf1df092dea72df276cc3/f7e02/type_checking2.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional API like Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import chain, Relu, Softmax\n",
    " \n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "\n",
    "model = chain(\n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Relu(nO=n_hidden, dropout=dropout), \n",
    "    Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operator Overloading\n",
    "\n",
    "I think this is a cool Thinc feature. Does something similar exist for PyTorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from thinc.api import Model, chain, Relu, Softmax\n",
    " \n",
    "n_hidden = 32\n",
    "dropout = 0.2\n",
    "\n",
    "with Model.define_operators({\">>\": chain}):\n",
    "    model = Relu(nO=n_hidden, dropout=dropout) >> Relu(nO=n_hidden, dropout=dropout) >> Softmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config file stuff\n",
    "\n",
    "**from docs:**\n",
    "\n",
    "Thinc provides a config system that lets you easily describe arbitrary trees of objects. The objects can be created via function calls you register using a simple decorator syntax. The config can include values like hyperparameters or training settings (whatever you need), or references to functions and the values of their arguments. Thinc will then construct the config bottom-up â€“ so you can define one function with its arguments, and then pass the return value into another function.\n",
    "\n",
    "--> I like this config as code concept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyper_params': {'learn_rate': 0.001},\n",
       " 'optimizer': {'@optimizers': 'Adam.v1', 'learn_rate': 0.001}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from thinc.api import Config, registry\n",
    "\n",
    "EXAMPLE_CONFIG1 = \"\"\"\n",
    "[hyper_params]\n",
    "learn_rate = 0.001\n",
    "\n",
    "[optimizer]\n",
    "@optimizers = \"Adam.v1\"\n",
    "learn_rate = ${hyper_params:learn_rate}\n",
    "\"\"\"\n",
    "\n",
    "config1 = Config().from_str(EXAMPLE_CONFIG1)\n",
    "config1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You can wrap TensorFlow, PyTorch and MXNet models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<thinc.model.Model at 0x7fc001202048>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from thinc.api import TensorFlowWrapper, Adam\n",
    "\n",
    "width = 32\n",
    "nO = 10\n",
    "nI = 784\n",
    "dropout = 0.2\n",
    "\n",
    "tf_model = Sequential()\n",
    "tf_model.add(Dense(width, activation=\"relu\", input_shape=(nI,)))\n",
    "tf_model.add(Dropout(dropout))\n",
    "tf_model.add(Dense(width, activation=\"relu\", input_shape=(nI,)))\n",
    "tf_model.add(Dropout(dropout))\n",
    "tf_model.add(Dense(nO, activation=\"softmax\"))\n",
    "\n",
    "wrapped_tf_model = TensorFlowWrapper(tf_model)\n",
    "wrapped_tf_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
